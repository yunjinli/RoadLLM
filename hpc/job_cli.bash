command="TRANSFORMERS_CACHE=/home/phd_li/.cache/huggingface/hub HF_HUB_OFFLINE=1 python -m llava.serve.cli_roadllm --conv-mode qwen_3 --model-base /home/phd_li/.cache/huggingface/hub/models--Qwen--Qwen3-8B/snapshots/b968826d9c46dd6066d109eabc6255188de91218 --model-path /home/phd_li/git_repo/RoadLLM/checkpoints/projectors/roadllm-llava-openai_clip-vit-large-patch14-336-Qwen_Qwen3-8B-mlp2x_gelu-pretrain-full-4gpus-5epoches --image-file /home/phd_li/git_repo/RoadLLM/test_images/urban.jpg"

bsub -Is -q gpu -gpu "num=1:j_exclusive=yes:gmem=40G" -R "select[type==X64LIN]" eval "${command}"